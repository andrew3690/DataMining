{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Trabalho_Final/State_of_data_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('P0', 'id')\n",
      "('P1_a ', 'Idade')\n",
      "('P1_a_1 ', 'Faixa idade')\n",
      "('P1_b ', 'Genero')\n",
      "('P1_c ', 'Cor/raca/etnia')\n",
      "('P1_d ', 'PCD')\n",
      "('P1_e ', 'experiencia_profissional_prejudicada')\n",
      "('P1_f ', 'aspectos_prejudicados')\n",
      "('P1_g ', 'vive_no_brasil')\n",
      "('P1_i ', 'Estado onde mora')\n",
      "('P1_i_1 ', 'uf onde mora')\n",
      "('P1_i_2 ', 'Regiao onde mora')\n",
      "('P1_j ', 'Mudou de Estado?')\n",
      "('P1_k ', 'Regiao de origem')\n",
      "('P1_l ', 'Nivel de Ensino')\n",
      "('P1_m ', 'Área de Formação')\n",
      "('P2_a ', 'Qual sua situação atual de trabalho?')\n",
      "('P2_b ', 'Setor')\n",
      "('P2_c ', 'Numero de Funcionarios')\n",
      "('P2_d ', 'Gestor?')\n",
      "('P2_e ', 'Cargo como Gestor')\n",
      "('P2_f ', 'Cargo Atual')\n",
      "('P2_g ', 'Nivel')\n",
      "('P2_h ', 'Faixa salarial')\n",
      "('P2_i ', 'Quanto tempo de experiência na área de dados você tem?')\n",
      "('P2_j ', 'Quanto tempo de experiência na área de TI/Engenharia de Software você teve antes de começar a trabalhar na área de dados?')\n",
      "('P2_k ', 'Você está satisfeito na sua empresa atual?')\n",
      "('P2_l ', 'Qual o principal motivo da sua insatisfação com a empresa atual?')\n",
      "('P2_l_1 ', 'Falta de oportunidade de crescimento no emprego atual')\n",
      "('P2_l_2 ', 'Salário atual não corresponde ao mercado')\n",
      "('P2_l_3 ', 'Não tenho uma boa relação com meu líder/gestor')\n",
      "('P2_l_4 ', 'Gostaria de trabalhar em em outra área de atuação')\n",
      "('P2_l_5 ', 'Gostaria de receber mais benefícios')\n",
      "('P2_l_6 ', 'O clima de trabalho/ambiente não é bom')\n",
      "('P2_l_7 ', 'Falta de maturidade analítica na empresa')\n",
      "('P2_m ', 'Você participou de entrevistas de emprego nos últimos 6 meses?')\n",
      "('P2_n ', 'Você pretende mudar de emprego nos próximos 6 meses?')\n",
      "('P2_o ', 'Quais os principais critérios que você leva em consideração no momento de decidir onde trabalhar?')\n",
      "('P2_o_1 ', 'Remuneração/Salário')\n",
      "('P2_o_2 ', 'Benefícios')\n",
      "('P2_o_3 ', 'Propósito do trabalho e da empresa')\n",
      "('P2_o_4 ', 'Flexibilidade de trabalho remoto')\n",
      "('P2_o_5 ', 'Ambiente e clima de trabalho')\n",
      "('P2_o_6 ', 'Oportunidade de aprendizado e trabalhar com referências na área')\n",
      "('P2_o_7 ', 'Plano de carreira e oportunidades de crescimento profissional')\n",
      "('P2_o_8 ', 'Maturidade da empresa em termos de tecnologia e dados')\n",
      "('P2_o_9 ', 'Qualidade dos gestores e líderes')\n",
      "('P2_o_10 ', 'Reputação que a empresa tem no mercado')\n",
      "('P2_p ', 'Atualmente qual a sua forma de trabalho?')\n",
      "('P2_q ', 'Qual a forma de trabalho ideal para você?')\n",
      "('P2_r ', 'Caso sua empresa decida pelo modelo 100% presencial qual será sua atitude?')\n",
      "('P2_s ', 'Sua empresa passu por Layoff em 2022?')\n",
      "('P3_a ', 'Qual o número aproximado de pessoas que atuam com dados na sua empresa hoje?')\n",
      "('P3_b ', 'Quais desses papéis/cargos fazem parte do time (ou chapter) de dados da sua empresa?')\n",
      "('P3_b_1 ', 'Analytics Engineer')\n",
      "('P3_b_2 ', 'Engenharia de Dados/Data Engineer')\n",
      "('P3_b_3 ', 'Analista de Dados/Data Analyst')\n",
      "('P3_b_4 ', 'Cientista de Dados/Data Scientist')\n",
      "('P3_b_5 ', 'Database Administrator/DBA')\n",
      "('P3_b_6 ', 'Analista de Business Intelligence/BI')\n",
      "('P3_b_7 ', 'Arquiteto de Dados/Data Architect')\n",
      "('P3_b_8 ', 'Data Product Manager/DPM')\n",
      "('P3_b_9 ', 'Business Analyst')\n",
      "('P3_c ', 'Quais dessas responsabilidades fazem parte da sua rotina atual de trabalho como gestor?')\n",
      "('P3_c_1 ', 'Pensar na visão de longo prazo de dados da empresa e fortalecimento da cultura analítica da companhia.')\n",
      "('P3_c_2 ', 'Organização de treinamentos e iniciativas com o objetivo de aumentar a maturidade analítica das áreas de negócios.')\n",
      "('P3_c_3 ', 'Atração, seleção e contratação de talentos para o time de dados.')\n",
      "('P3_c_4 ', 'Decisão sobre contratação de ferramentas e tecnologias relacionadas a dados.')\n",
      "('P3_c_5 ', 'Sou gestor da equipe responsável pela engenharia de dados e por manter o Data Lake da empresa como fonte única dos dados, garantindo a qualidade e confiabilidade da informação.')\n",
      "('P3_c_6 ', 'Sou gestor da equipe responsável pela entrega de dados, estudos, relatórios e dashboards para as áreas de negócio da empresa.')\n",
      "('P3_c_7 ', 'Sou gestor da equipe responsável por iniciativas e projetos envolvendo Inteligência Artificial e Machine Learning.')\n",
      "('P3_c_8 ', 'Apesar de ser gestor ainda atuo na parte técnica, construindo soluções/análises/modelos etc.')\n",
      "('P3_c_9 ', 'Gestão de projetos de dados, cuidando das etapas, equipes envolvidas, atingimento dos objetivos etc.')\n",
      "('P3_c_10 ', 'Gestão de produtos de dados, cuidando da visão dos produtos, backlog, feedback de usuários etc.')\n",
      "('P3_c_11 ', 'Gestão de pessoas, apoio no desenvolvimento das pessoas, evolução de carreira')\n",
      "('P3_d ', 'Quais são os 3 maiores desafios que você tem como gestor no atual momento?')\n",
      "('P3_d_1 ', 'a Contratar novos talentos.')\n",
      "('P3_d_2 ', 'b Reter talentos.')\n",
      "('P3_d_3 ', 'c Convencer a empresa a aumentar os investimentos na área de dados.')\n",
      "('P3_d_4 ', 'd Gestão de equipes no ambiente remoto.')\n",
      "('P3_d_5 ', 'e Gestão de projetos envolvendo áreas multidisciplinares da empresa.')\n",
      "('P3_d_6 ', 'f Organizar as informações e garantir a qualidade e confiabilidade.')\n",
      "('P3_d_7 ', 'g Conseguir processar e armazenar um alto volume de dados.')\n",
      "('P3_d_8 ', 'h Conseguir gerar valor para as áreas de negócios através de estudos e experimentos.')\n",
      "('P3_d_9 ', 'i Desenvolver e manter modelos Machine Learning em produção.')\n",
      "('P3_d_10 ', 'j Gerenciar a expectativa das áreas de negócio em relação as entregas das equipes de dados.')\n",
      "('P3_d_11 ', 'k Garantir a manutenção dos projetos e modelos em produção, em meio ao crescimento da empresa.')\n",
      "('P3_d_12 ', 'Conseguir levar inovação para a empresa através dos dados.')\n",
      "('P3_d_13 ', 'Garantir retorno do investimento (ROI) em projetos de dados.')\n",
      "('P3_d_14 ', 'Dividir o tempo entre entregas técnicas e gestão.')\n",
      "('P4_a ', 'Mesmo que esse não seja seu cargo formal, você considera que sua atuação no dia a dia, reflete alguma das opções listadas abaixo?')\n",
      "('P4_a_1 ', 'Atuacao')\n",
      "('P4_b ', 'Quais das fontes de dados listadas você já analisou ou processou no trabalho?')\n",
      "('P4_b_1 ', 'Dados relacionais (estruturados em bancos SQL)')\n",
      "('P4_b_2 ', 'Dados armazenados em bancos NoSQL')\n",
      "('P4_b_3 ', 'Imagens')\n",
      "('P4_b_4 ', 'Textos/Documentos')\n",
      "('P4_b_5 ', 'Vídeos')\n",
      "('P4_b_6 ', 'Áudios')\n",
      "('P4_b_7 ', 'Planilhas')\n",
      "('P4_b_8 ', 'Dados georeferenciados')\n",
      "('P4_c ', 'Entre as fontes de dados listadas, quais você utiliza na maior parte do tempo?')\n",
      "('P4_c_1 ', 'Dados relacionais (estruturados em bancos SQL)')\n",
      "('P4_c_2 ', 'Dados armazenados em bancos NoSQL')\n",
      "('P4_c_3 ', 'Imagens')\n",
      "('P4_c_4 ', 'Textos/Documentos')\n",
      "('P4_c_5 ', 'Vídeos')\n",
      "('P4_c_6 ', 'Áudios')\n",
      "('P4_c_7 ', 'Planilhas')\n",
      "('P4_c_8 ', 'Dados georeferenciados')\n",
      "('P4_d ', 'Quais das linguagens listadas abaixo você utiliza no trabalho?')\n",
      "('P4_d_1 ', 'SQL')\n",
      "('P4_d_2 ', 'R ')\n",
      "('P4_d_3 ', 'Python')\n",
      "('P4_d_4 ', 'C/C++/C#')\n",
      "('P4_d_5 ', '.NET')\n",
      "('P4_d_6 ', 'Java')\n",
      "('P4_d_7 ', 'Julia')\n",
      "('P4_d_8 ', 'SAS/Stata')\n",
      "('P4_d_9 ', 'Visual Basic/VBA')\n",
      "('P4_d_10 ', 'Scala')\n",
      "('P4_d_11 ', 'Matlab')\n",
      "('P4_d_12 ', 'PHP')\n",
      "('P4_d_13 ', 'Javascript')\n",
      "('P4_d_14 ', 'Não utilizo nenhuma linguagem')\n",
      "('P4_e ', 'Entre as linguagens listadas abaixo, qual é a que você mais utiliza no trabalho?')\n",
      "('P4_f ', 'Entre as linguagens listadas abaixo, qual é a sua preferida?')\n",
      "('P4_g ', 'Quais dos bancos de dados/fontes de dados listados abaixo você utiliza no trabalho?')\n",
      "('P4_g_1 ', 'MySQL')\n",
      "('P4_g_2 ', 'Oracle')\n",
      "('P4_g_3 ', 'SQL SERVER')\n",
      "('P4_f_4 ', 'Amazon Aurora ou RDS')\n",
      "('P4_f_5 ', 'DynamoDB')\n",
      "('P4_f_6 ', 'CoachDB')\n",
      "('P4_f_7 ', 'Cassandra')\n",
      "('P4_f_8 ', 'MongoDB')\n",
      "('P4_f_9 ', 'MariaDB')\n",
      "('P4_f_10 ', 'Datomic')\n",
      "('P4_f_11 ', 'S3')\n",
      "('P4_f_12 ', 'PostgreSQL')\n",
      "('P4_f_13 ', 'ElasticSearch')\n",
      "('P4_f_14 ', 'DB2')\n",
      "('P4_f_15 ', 'Microsoft Access')\n",
      "('P4_f_16 ', 'SQLite')\n",
      "('P4_f_17 ', 'Sybase')\n",
      "('P4_f_18 ', 'Firebase')\n",
      "('P4_f_19 ', 'Vertica')\n",
      "('P4_f_20 ', 'Redis')\n",
      "('P4_f_21 ', 'Neo4J')\n",
      "('P4_f_22 ', 'Google BigQuery')\n",
      "('P4_f_23 ', 'Google Firestore')\n",
      "('P4_f_24 ', 'Amazon Redshift')\n",
      "('P4_f_25 ', 'Amazon Athena')\n",
      "('P4_f_26 ', 'Snowflake')\n",
      "('P4_f_27 ', 'Databricks')\n",
      "('P4_f_28 ', 'HBase')\n",
      "('P4_f_29 ', 'Presto')\n",
      "('P4_f_30 ', 'Splunk')\n",
      "('P4_f_31 ', 'SAP HANA')\n",
      "('P4_f_32 ', 'Hive')\n",
      "('P4_f_33 ', 'Firebird')\n",
      "('P4_g ', 'Quais das opções de Cloud listadas abaixo você utiliza no trabalho?')\n",
      "('P4_h ', 'Dentre as opções listadas, qual sua Cloud preferida?')\n",
      "('P4_h_1 ', 'Azure (Microsoft)')\n",
      "('P4_h_2 ', 'Amazon Web Services (AWS)')\n",
      "('P4_h_3 ', 'Google Cloud (GCP)')\n",
      "('P4_i ', 'Microsoft PowerBI')\n",
      "('P4_i_1 ', 'Microsoft PowerBI')\n",
      "('P4_i_2 ', 'Qlik View/Qlik Sense')\n",
      "('P4_i_3 ', 'Tableau')\n",
      "('P4_i_4 ', 'Metabase')\n",
      "('P4_i_5 ', 'Superset')\n",
      "('P4_i_6 ', 'Redash')\n",
      "('P4_i_7 ', 'MicroStrategy')\n",
      "('P4_i_8 ', 'IBM Analytics/Cognos')\n",
      "('P4_i_9 ', 'SAP Business Objects')\n",
      "('P4_i_10 ', 'Oracle Business Intelligence')\n",
      "('P4_i_11 ', 'Amazon QuickSight')\n",
      "('P4_i_12 ', 'Salesforce/Einstein Analytics')\n",
      "('P4_i_13 ', 'Mode')\n",
      "('P4_i_14 ', 'Alteryx')\n",
      "('P4_i_15 ', 'Birst')\n",
      "('P4_i_16 ', 'Looker')\n",
      "('P4_i_17 ', 'Google Data Studio')\n",
      "('P4_i_18 ', 'SAS Visual Analytics')\n",
      "('P4_i_19 ', 'Grafana')\n",
      "('P4_i_20 ', 'TIBCO Spotfire')\n",
      "('P4_i_21 ', 'Pentaho')\n",
      "('P4_i_22 ', 'Fazemos todas as análises utilizando apenas Excel ou planilhas do google')\n",
      "('P4_i_23 ', 'Não utilizo nenhuma ferramenta de BI no trabalho')\n",
      "('P5_a ', 'Qual seu objetivo na área de dados?')\n",
      "('P5_b ', 'Qual oportunidade você está buscando?')\n",
      "('P5_c ', 'Há quanto tempo você busca uma oportunidade na área de dados?')\n",
      "('P5_d ', 'Como tem sido a busca por um emprego na área de dados?')\n",
      "('P6_a ', 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual como engenheiro de dados?')\n",
      "('P6_a_1 ', 'Desenvolvo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc.')\n",
      "('P6_a_2 ', 'Realizo construções de ETL's em ferramentas como Pentaho, Talend, Dataflow etc.')\n",
      "('P6_a_3 ', 'Crio consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\n",
      "('P6_a_4 ', 'Atuo na integração de diferentes fontes de dados através de plataformas proprietárias como Stitch Data, Fivetran etc.')\n",
      "('P6_a_5 ', 'Modelo soluções de arquitetura de dados, criando componentes de ingestão de dados, transformação e recuperação da informação.')\n",
      "('P6_a_6 ', 'Desenvolvo/cuido da manutenção de repositórios de dados baseados em streaming de eventos como Data Lakes e Data Lakehouses.')\n",
      "('P6_a_7 ', 'Atuo na modelagem dos dados, com o objetivo de criar conjuntos de dados como Data Warehouses, Data Marts etc.')\n",
      "('P6_a_8 ', 'Cuido da qualidade dos dados, metadados e dicionário de dados.')\n",
      "('P6_a_9 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\n",
      "('P6_b ', 'Quais as ferramentas/tecnologias de ETL que você utiliza no trabalho como Data Engineer?')\n",
      "('P6_b_1 ', 'Scripts Python')\n",
      "('P6_b_2 ', 'SQL & Stored Procedures')\n",
      "('P6_b_3 ', 'Apache Airflow')\n",
      "('P6_b_4 ', 'Luigi')\n",
      "('P6_b_5 ', 'AWS Glue')\n",
      "('P6_b_6 ', 'Talend')\n",
      "('P6_b_7 ', 'Pentaho')\n",
      "('P6_b_8 ', 'Alteryx')\n",
      "('P6_b_9 ', 'Stitch')\n",
      "('P6_b_10 ', 'Fivetran')\n",
      "('P6_b_11 ', 'Google Dataflow')\n",
      "('P6_b_12 ', 'Oracle Data Integrator')\n",
      "('P6_b_13 ', 'IBM DataStage')\n",
      "('P6_b_14 ', 'SAP BW ETL')\n",
      "('P6_b_15 ', 'SQL Server Integration Services (SSIS)')\n",
      "('P6_b_16 ', 'SAS Data Integration')\n",
      "('P6_b_17 ', 'Qlik Sense')\n",
      "('P6_b_18 ', 'Knime')\n",
      "('P6_b_19 ', 'Databricks')\n",
      "('P6_b_19 ', 'Não utilizo ferramentas de ETL')\n",
      "('P6_c ', 'Sua organização possui um Data Lake?')\n",
      "('P6_d ', 'Qual tecnologia utilizada como plataforma do Data Lake?')\n",
      "('P6_e ', 'Sua organização possui um Data Warehouse?')\n",
      "('P6_f ', 'Qual tecnologia utilizada como plataforma do Data Warehouse?')\n",
      "('P6_g ', 'Quais as ferramentas de gestão de Qualidade de dados, Metadados e catálogo de dados você utiliza no trabalho?')\n",
      "('P6_g_1 ', 'great_expectations')\n",
      "('P6_g_2 ', 'dbt')\n",
      "('P6_g_3 ', 'AWS Deequ')\n",
      "('P6_g_4 ', 'Apache Griffin')\n",
      "('P6_g_5 ', 'Datafold')\n",
      "('P6_g_6 ', 'Amundsen')\n",
      "('P6_g_7 ', 'Monte Carlo')\n",
      "('P6_g_8 ', 'SODA')\n",
      "('P6_g_9 ', 'Big Eye')\n",
      "('P6_g_10 ', 'Data Band')\n",
      "('P6_g_11 ', 'Anomalo')\n",
      "('P6_g_l ', 'Metaplane')\n",
      "('P6_g_m ', 'Acceldata')\n",
      "('P6_h ', 'Em qual das opções abaixo você gasta a maior parte do seu tempo?')\n",
      "('P6_h_1 ', 'Desenvolvendo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc.')\n",
      "('P6_h_2 ', 'Realizando construções de ETL's em ferramentas como Pentaho, Talend, Dataflow etc.')\n",
      "('P6_h_3 ', 'Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\n",
      "('P6_h_4 ', 'Atuando na integração de diferentes fontes de dados através de plataformas proprietárias como Stitch Data, Fivetran etc.')\n",
      "('P6_h_5 ', 'Modelando soluções de arquitetura de dados, criando componentes de ingestão de dados, transformação e recuperação da informação.')\n",
      "('P6_h_6 ', 'Desenvolvendo/cuidando da manutenção de repositórios de dados baseados em streaming de eventos como Data Lakes e Data Lakehouses.')\n",
      "('P6_h_7 ', 'Atuando na modelagem dos dados, com o objetivo de criar conjuntos de dados como Data Warehouses, Data Marts etc.')\n",
      "('P6_h_8 ', 'Cuidando da qualidade dos dados, metadados e dicionário de dados.')\n",
      "('P6_h_9 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\n",
      "('P7_1 ', 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual com análise de dados?')\n",
      "('P7_a_1 ', 'Processo e analiso dados utilizando linguagens de programação como Python, R etc.')\n",
      "('P7_a_2 ', 'Realizo construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik etc.')\n",
      "('P7_a_3 ', 'Crio consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\n",
      "('P7_a_4 ', 'Utilizo API's para extrair dados e complementar minhas análises.')\n",
      "('P7_a_5 ', 'Realizo experimentos e estudos utilizando metodologias estatísticas como teste de hipótese, modelos de regressão etc.')\n",
      "('P7_a_6 ', 'Desenvolvo/cuido da manutenção de ETL's utilizando tecnologias como Talend, Pentaho, Airflow, Dataflow etc.')\n",
      "('P7_a_7 ', 'Atuo na modelagem dos dados, com o objetivo de criar conjuntos de dados, Data Warehouses, Data Marts etc.')\n",
      "('P7_a_8 ', 'Desenvolvo/cuido da manutenção de planilhas para atender as áreas de negócio.')\n",
      "('P7_a_9 ', 'Utilizo ferramentas avançadas de estatística como SAS')\n",
      "('P7_a_10 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\n",
      "('P7_b ', 'Quais as ferramentas/tecnologias de ETL que você utiliza no trabalho como Data Analyst?')\n",
      "('P7_b_1 ', 'Scripts Python')\n",
      "('P7_b_2 ', 'SQL & Stored Procedures')\n",
      "('P7_b_3 ', 'Apache Airflow')\n",
      "('P7_b_4 ', 'Luigi')\n",
      "('P7_b_5 ', 'AWS Glue')\n",
      "('P7_b_6 ', 'Talend')\n",
      "('P7_b_7 ', 'Pentaho')\n",
      "('P7_b_8 ', 'Alteryx')\n",
      "('P7_b_9 ', 'Stitch')\n",
      "('P7_b_10 ', 'Fivetran')\n",
      "('P7_b_11 ', 'Google Dataflow')\n",
      "('P7_b_12 ', 'Oracle Data Integrator')\n",
      "('P7_b_13 ', 'IBM DataStage')\n",
      "('P7_b_14 ', 'SAP BW ETL')\n",
      "('P7_b_15 ', 'SQL Server Integration Services (SSIS)')\n",
      "('P7_b_16 ', 'SAS Data Integration')\n",
      "('P7_b_17 ', 'Qlik Sense')\n",
      "('P7_b_18 ', 'Knime')\n",
      "('P7_b_19 ', 'Databricks')\n",
      "('P7_b_20 ', 'Não utilizo ferramentas de ETL')\n",
      "('P7_c ', 'Sua empresa utiliza alguma das ferramentas listadas para dar mais autonomia em análise de dados para as áreas de negócio?')\n",
      "('P7_c_1 ', 'Ferramentas de AutoML como H2O.ai, Data Robot, BigML etc.')\n",
      "('P7_c_2 ', '\"\"Point and Click\"\" Analytics como Alteryx, Knime, Rapidminer etc.')\n",
      "('P7_c_3 ', 'Product metricts & Insights como Mixpanel, Amplitude, Adobe Analytics.')\n",
      "('P7_c_4 ', 'Ferramentas de análise dentro de ferramentas de CRM como Salesforce Einstein Anaytics ou Zendesk dashboards.')\n",
      "('P7_c_5 ', 'Minha empresa não utiliza essas ferramentas.')\n",
      "('P7_c_6 ', 'Não sei informar.')\n",
      "('P7_d ', 'Em qual das opções abaixo você gasta a maior parte do seu tempo de trabalho?')\n",
      "('P7_d_1 ', 'Processando e analisando dados utilizando linguagens de programação como Python, R etc.')\n",
      "('P7_d_2 ', 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik etc.')\n",
      "('P7_d_3 ', 'Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\n",
      "('P7_d_4 ', 'Utilizando API's para extrair dados e complementar minhas análises.')\n",
      "('P7_d_5 ', 'Realizando experimentos e estudos utilizando metodologias estatísticas como teste de hipótese, modelos de regressão etc.')\n",
      "('P7_d_6 ', 'Desenvolvendo/cuidando da manutenção de ETL's utilizando tecnologias como Talend, Pentaho, Airflow, Dataflow etc.')\n",
      "('P7_d_7 ', 'Atuando na modelagem dos dados, com o objetivo de criar conjuntos de dados, Data Warehouses, Data Marts etc.')\n",
      "('P7_d_8 ', 'Desenvolvendo/cuidando da manutenção de planilhas do Excel ou Google Sheets para atender as áreas de negócio.')\n",
      "('P7_d_9 ', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.')\n",
      "('P7_d_10 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\n",
      "('P8_a ', 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual com ciência de dados?')\n",
      "('P8_a_1 ', 'Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar modelos preditivos, forecasts, análise de cluster para resolver problemas pontuais e responder perguntas das áreas de negócio.')\n",
      "('P8_a_2 ', 'Sou responsável pela coleta e limpeza dos dados que uso para análise e modelagem.')\n",
      "('P8_a_3 ', 'Sou responsável por entrar em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.')\n",
      "('P8_a_4 ', 'Desenvolvo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).')\n",
      "('P8_a_5 ', 'Sou responsável por colocar modelos em produção, criar os pipelines de dados, APIs de consumo e monitoramento.')\n",
      "('P8_a_6 ', 'Cuido da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.')\n",
      "('P8_a_7 ', 'Realizo construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc')\n",
      "('P8_a_8 ', 'Utilizo ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises estatísticas e ajustar modelos.Crio e dou manutenção em ETLs, DAGs e automações de pipelines de dados.')\n",
      "('P8_a_9 ', 'Crio e dou manutenção em ETLs, DAGs e automações de pipelines de dados.')\n",
      "('P8_a_10 ', 'Crio e gerencio soluções de Feature Store e cultura de MLOps.')\n",
      "('P8_a_11 ', 'Sou responsável por criar e manter a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.)')\n",
      "('P8_b ', 'Quais as técnicas e métodos listados abaixo você costuma utilizar no trabalho?')\n",
      "('P8_b_1 ', 'Utilizo modelos de regressão (linear, logística, GLM)')\n",
      "('P8_b_2 ', 'Utilizo redes neurais ou modelos baseados em árvore para criar modelos de classificação')\n",
      "('P8_b_3 ', 'Desenvolvo sistemas de recomendação (RecSys)')\n",
      "('P8_b_4 ', 'Utilizo métodos estatísticos Bayesianos para analisar dados')\n",
      "('P8_b_5 ', 'Utilizo técnicas de NLP (Natural Language Processing) para análisar dados não-estruturados')\n",
      "('P8_b_6 ', 'Utilizo métodos estatísticos clássicos (Testes de hipótese, análise multivariada, sobrevivência, dados longitudinais, inferência estatistica) para analisar dados')\n",
      "('P8_b_7 ', 'Utilizo cadeias de Markov ou HMM's para realizar análises de dados')\n",
      "('P8_b_8 ', 'Desenvolvo técnicas de Clusterização (K-means, Spectral, DBScan etc)')\n",
      "('P8_b_9 ', 'Realizo previsões através de modelos de Séries Temporais (Time Series)')\n",
      "('P8_b_10 ', 'Utilizo modelos de Reinforcement Learning (aprendizado por reforço)')\n",
      "('P8_b_11 ', 'Utilizo modelos de Machine Learning para detecção de fraude')\n",
      "('P8_b_l ', 'Utilizo métodos de Visão Computacional')\n",
      "('P8_b_m ', 'Utilizo modelos de Detecção de Churn')\n",
      "('P8_3 ', 'Quais dessas tecnologias fazem parte do seu dia a dia como cientista de dados?')\n",
      "('P8_c_1 ', 'Ferramentas de BI (PowerBI, Looker, Tableau, Qlik etc)')\n",
      "('P8_c_2 ', 'Planilhas (Excel, Google Sheets etc)')\n",
      "('P8_c_3 ', 'Ambientes de desenvolvimento local (R-studio, JupyterLab, Anaconda)')\n",
      "('P8_c_4 ', 'Ambientes de desenvolvimento na nuvem (Google Colab, AWS Sagemaker, Kaggle Notebooks etc)')\n",
      "('P8_c_5 ', 'Ferramentas de AutoML (Datarobot, H2O, Auto-Keras etc)')\n",
      "('P8_c_6 ', 'Ferramentas de ETL (Apache Airflow, NiFi, Stitch, Fivetran, Pentaho etc)')\n",
      "('P8_c_7 ', 'Plataformas de Machine Learning (TensorFlow, Azure Machine Learning, Kubeflow etc)')\n",
      "('P8_c_8 ', 'Feature Store (Feast, Hopsworks, AWS Feature Store, Databricks Feature Store etc)')\n",
      "('P8_c_9 ', 'Sistemas de controle de versão (Github, DVC, Neptune, Gitlab etc)')\n",
      "('P8_c_10 ', 'Plataformas de Data Apps (Streamlit, Shiny, Plotly Dash etc)')\n",
      "('P8_c_11 ', 'Ferramentas de estatística avançada como SPSS, SAS, etc.')\n",
      "('P8_d ', 'Em qual das opções abaixo você gasta a maior parte do seu tempo no trabalho?')\n",
      "('P8_d_1 ', 'Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar modelos preditivos, forecasts, análise de cluster para resolver problemas pontuais e responder perguntas das áreas de negócio.')\n",
      "('P8_d_2 ', 'Coletando e limpando os dados que uso para análise e modelagem.')\n",
      "('P8_d_3 ', 'Entrando em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.')\n",
      "('P8_d_4 ', 'Desenvolvendo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).')\n",
      "('P8_d_5 ', 'Colocando modelos em produção, criando os pipelines de dados, APIs de consumo e monitoramento.')\n",
      "('P8_d_6 ', 'Cuidando da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.')\n",
      "('P8_d_7 ', 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc.')\n",
      "('P8_d_8 ', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.')\n",
      "('P8_d_9 ', 'Criando e dando manutenção em ETLs, DAGs e automações de pipelines de dados.')\n",
      "('P8_d_10 ', 'Criando e gerenciando soluções de Feature Store e cultura de MLOps.')\n",
      "('P8_d_11 ', 'Criando e mantendo a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.)')\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns: \n",
    "    print(col)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values_between_parentheses(dataframe):\n",
    "    # Define the list of columns to extract\n",
    "    columns_to_extract = dataframe.columns\n",
    "\n",
    "    for col in columns_to_extract:\n",
    "        print(col)\n",
    "        # result_dict[col[1]] = dataframe[col[0]].str.extract(r'\\((.*?)\\)')\n",
    "\n",
    "\n",
    "    # # Convert the result to a DataFrame\n",
    "    # result_df = pd.DataFrame(result_dict)\n",
    "\n",
    "    # return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('P0', 'id')\n",
      "('P1_a ', 'Idade')\n",
      "('P1_a_1 ', 'Faixa idade')\n",
      "('P1_b ', 'Genero')\n",
      "('P1_c ', 'Cor/raca/etnia')\n",
      "('P1_d ', 'PCD')\n",
      "('P1_e ', 'experiencia_profissional_prejudicada')\n",
      "('P1_f ', 'aspectos_prejudicados')\n",
      "('P1_g ', 'vive_no_brasil')\n",
      "('P1_i ', 'Estado onde mora')\n",
      "('P1_i_1 ', 'uf onde mora')\n",
      "('P1_i_2 ', 'Regiao onde mora')\n",
      "('P1_j ', 'Mudou de Estado?')\n",
      "('P1_k ', 'Regiao de origem')\n",
      "('P1_l ', 'Nivel de Ensino')\n",
      "('P1_m ', 'Área de Formação')\n",
      "('P2_a ', 'Qual sua situação atual de trabalho?')\n",
      "('P2_b ', 'Setor')\n",
      "('P2_c ', 'Numero de Funcionarios')\n",
      "('P2_d ', 'Gestor?')\n",
      "('P2_e ', 'Cargo como Gestor')\n",
      "('P2_f ', 'Cargo Atual')\n",
      "('P2_g ', 'Nivel')\n",
      "('P2_h ', 'Faixa salarial')\n",
      "('P2_i ', 'Quanto tempo de experiência na área de dados você tem?')\n",
      "('P2_j ', 'Quanto tempo de experiência na área de TI/Engenharia de Software você teve antes de começar a trabalhar na área de dados?')\n",
      "('P2_k ', 'Você está satisfeito na sua empresa atual?')\n",
      "('P2_l ', 'Qual o principal motivo da sua insatisfação com a empresa atual?')\n",
      "('P2_l_1 ', 'Falta de oportunidade de crescimento no emprego atual')\n",
      "('P2_l_2 ', 'Salário atual não corresponde ao mercado')\n",
      "('P2_l_3 ', 'Não tenho uma boa relação com meu líder/gestor')\n",
      "('P2_l_4 ', 'Gostaria de trabalhar em em outra área de atuação')\n",
      "('P2_l_5 ', 'Gostaria de receber mais benefícios')\n",
      "('P2_l_6 ', 'O clima de trabalho/ambiente não é bom')\n",
      "('P2_l_7 ', 'Falta de maturidade analítica na empresa')\n",
      "('P2_m ', 'Você participou de entrevistas de emprego nos últimos 6 meses?')\n",
      "('P2_n ', 'Você pretende mudar de emprego nos próximos 6 meses?')\n",
      "('P2_o ', 'Quais os principais critérios que você leva em consideração no momento de decidir onde trabalhar?')\n",
      "('P2_o_1 ', 'Remuneração/Salário')\n",
      "('P2_o_2 ', 'Benefícios')\n",
      "('P2_o_3 ', 'Propósito do trabalho e da empresa')\n",
      "('P2_o_4 ', 'Flexibilidade de trabalho remoto')\n",
      "('P2_o_5 ', 'Ambiente e clima de trabalho')\n",
      "('P2_o_6 ', 'Oportunidade de aprendizado e trabalhar com referências na área')\n",
      "('P2_o_7 ', 'Plano de carreira e oportunidades de crescimento profissional')\n",
      "('P2_o_8 ', 'Maturidade da empresa em termos de tecnologia e dados')\n",
      "('P2_o_9 ', 'Qualidade dos gestores e líderes')\n",
      "('P2_o_10 ', 'Reputação que a empresa tem no mercado')\n",
      "('P2_p ', 'Atualmente qual a sua forma de trabalho?')\n",
      "('P2_q ', 'Qual a forma de trabalho ideal para você?')\n",
      "('P2_r ', 'Caso sua empresa decida pelo modelo 100% presencial qual será sua atitude?')\n",
      "('P2_s ', 'Sua empresa passu por Layoff em 2022?')\n",
      "('P3_a ', 'Qual o número aproximado de pessoas que atuam com dados na sua empresa hoje?')\n",
      "('P3_b ', 'Quais desses papéis/cargos fazem parte do time (ou chapter) de dados da sua empresa?')\n",
      "('P3_b_1 ', 'Analytics Engineer')\n",
      "('P3_b_2 ', 'Engenharia de Dados/Data Engineer')\n",
      "('P3_b_3 ', 'Analista de Dados/Data Analyst')\n",
      "('P3_b_4 ', 'Cientista de Dados/Data Scientist')\n",
      "('P3_b_5 ', 'Database Administrator/DBA')\n",
      "('P3_b_6 ', 'Analista de Business Intelligence/BI')\n",
      "('P3_b_7 ', 'Arquiteto de Dados/Data Architect')\n",
      "('P3_b_8 ', 'Data Product Manager/DPM')\n",
      "('P3_b_9 ', 'Business Analyst')\n",
      "('P3_c ', 'Quais dessas responsabilidades fazem parte da sua rotina atual de trabalho como gestor?')\n",
      "('P3_c_1 ', 'Pensar na visão de longo prazo de dados da empresa e fortalecimento da cultura analítica da companhia.')\n",
      "('P3_c_2 ', 'Organização de treinamentos e iniciativas com o objetivo de aumentar a maturidade analítica das áreas de negócios.')\n",
      "('P3_c_3 ', 'Atração, seleção e contratação de talentos para o time de dados.')\n",
      "('P3_c_4 ', 'Decisão sobre contratação de ferramentas e tecnologias relacionadas a dados.')\n",
      "('P3_c_5 ', 'Sou gestor da equipe responsável pela engenharia de dados e por manter o Data Lake da empresa como fonte única dos dados, garantindo a qualidade e confiabilidade da informação.')\n",
      "('P3_c_6 ', 'Sou gestor da equipe responsável pela entrega de dados, estudos, relatórios e dashboards para as áreas de negócio da empresa.')\n",
      "('P3_c_7 ', 'Sou gestor da equipe responsável por iniciativas e projetos envolvendo Inteligência Artificial e Machine Learning.')\n",
      "('P3_c_8 ', 'Apesar de ser gestor ainda atuo na parte técnica, construindo soluções/análises/modelos etc.')\n",
      "('P3_c_9 ', 'Gestão de projetos de dados, cuidando das etapas, equipes envolvidas, atingimento dos objetivos etc.')\n",
      "('P3_c_10 ', 'Gestão de produtos de dados, cuidando da visão dos produtos, backlog, feedback de usuários etc.')\n",
      "('P3_c_11 ', 'Gestão de pessoas, apoio no desenvolvimento das pessoas, evolução de carreira')\n",
      "('P3_d ', 'Quais são os 3 maiores desafios que você tem como gestor no atual momento?')\n",
      "('P3_d_1 ', 'a Contratar novos talentos.')\n",
      "('P3_d_2 ', 'b Reter talentos.')\n",
      "('P3_d_3 ', 'c Convencer a empresa a aumentar os investimentos na área de dados.')\n",
      "('P3_d_4 ', 'd Gestão de equipes no ambiente remoto.')\n",
      "('P3_d_5 ', 'e Gestão de projetos envolvendo áreas multidisciplinares da empresa.')\n",
      "('P3_d_6 ', 'f Organizar as informações e garantir a qualidade e confiabilidade.')\n",
      "('P3_d_7 ', 'g Conseguir processar e armazenar um alto volume de dados.')\n",
      "('P3_d_8 ', 'h Conseguir gerar valor para as áreas de negócios através de estudos e experimentos.')\n",
      "('P3_d_9 ', 'i Desenvolver e manter modelos Machine Learning em produção.')\n",
      "('P3_d_10 ', 'j Gerenciar a expectativa das áreas de negócio em relação as entregas das equipes de dados.')\n",
      "('P3_d_11 ', 'k Garantir a manutenção dos projetos e modelos em produção, em meio ao crescimento da empresa.')\n",
      "('P3_d_12 ', 'Conseguir levar inovação para a empresa através dos dados.')\n",
      "('P3_d_13 ', 'Garantir retorno do investimento (ROI) em projetos de dados.')\n",
      "('P3_d_14 ', 'Dividir o tempo entre entregas técnicas e gestão.')\n",
      "('P4_a ', 'Mesmo que esse não seja seu cargo formal, você considera que sua atuação no dia a dia, reflete alguma das opções listadas abaixo?')\n",
      "('P4_a_1 ', 'Atuacao')\n",
      "('P4_b ', 'Quais das fontes de dados listadas você já analisou ou processou no trabalho?')\n",
      "('P4_b_1 ', 'Dados relacionais (estruturados em bancos SQL)')\n",
      "('P4_b_2 ', 'Dados armazenados em bancos NoSQL')\n",
      "('P4_b_3 ', 'Imagens')\n",
      "('P4_b_4 ', 'Textos/Documentos')\n",
      "('P4_b_5 ', 'Vídeos')\n",
      "('P4_b_6 ', 'Áudios')\n",
      "('P4_b_7 ', 'Planilhas')\n",
      "('P4_b_8 ', 'Dados georeferenciados')\n",
      "('P4_c ', 'Entre as fontes de dados listadas, quais você utiliza na maior parte do tempo?')\n",
      "('P4_c_1 ', 'Dados relacionais (estruturados em bancos SQL)')\n",
      "('P4_c_2 ', 'Dados armazenados em bancos NoSQL')\n",
      "('P4_c_3 ', 'Imagens')\n",
      "('P4_c_4 ', 'Textos/Documentos')\n",
      "('P4_c_5 ', 'Vídeos')\n",
      "('P4_c_6 ', 'Áudios')\n",
      "('P4_c_7 ', 'Planilhas')\n",
      "('P4_c_8 ', 'Dados georeferenciados')\n",
      "('P4_d ', 'Quais das linguagens listadas abaixo você utiliza no trabalho?')\n",
      "('P4_d_1 ', 'SQL')\n",
      "('P4_d_2 ', 'R ')\n",
      "('P4_d_3 ', 'Python')\n",
      "('P4_d_4 ', 'C/C++/C#')\n",
      "('P4_d_5 ', '.NET')\n",
      "('P4_d_6 ', 'Java')\n",
      "('P4_d_7 ', 'Julia')\n",
      "('P4_d_8 ', 'SAS/Stata')\n",
      "('P4_d_9 ', 'Visual Basic/VBA')\n",
      "('P4_d_10 ', 'Scala')\n",
      "('P4_d_11 ', 'Matlab')\n",
      "('P4_d_12 ', 'PHP')\n",
      "('P4_d_13 ', 'Javascript')\n",
      "('P4_d_14 ', 'Não utilizo nenhuma linguagem')\n",
      "('P4_e ', 'Entre as linguagens listadas abaixo, qual é a que você mais utiliza no trabalho?')\n",
      "('P4_f ', 'Entre as linguagens listadas abaixo, qual é a sua preferida?')\n",
      "('P4_g ', 'Quais dos bancos de dados/fontes de dados listados abaixo você utiliza no trabalho?')\n",
      "('P4_g_1 ', 'MySQL')\n",
      "('P4_g_2 ', 'Oracle')\n",
      "('P4_g_3 ', 'SQL SERVER')\n",
      "('P4_f_4 ', 'Amazon Aurora ou RDS')\n",
      "('P4_f_5 ', 'DynamoDB')\n",
      "('P4_f_6 ', 'CoachDB')\n",
      "('P4_f_7 ', 'Cassandra')\n",
      "('P4_f_8 ', 'MongoDB')\n",
      "('P4_f_9 ', 'MariaDB')\n",
      "('P4_f_10 ', 'Datomic')\n",
      "('P4_f_11 ', 'S3')\n",
      "('P4_f_12 ', 'PostgreSQL')\n",
      "('P4_f_13 ', 'ElasticSearch')\n",
      "('P4_f_14 ', 'DB2')\n",
      "('P4_f_15 ', 'Microsoft Access')\n",
      "('P4_f_16 ', 'SQLite')\n",
      "('P4_f_17 ', 'Sybase')\n",
      "('P4_f_18 ', 'Firebase')\n",
      "('P4_f_19 ', 'Vertica')\n",
      "('P4_f_20 ', 'Redis')\n",
      "('P4_f_21 ', 'Neo4J')\n",
      "('P4_f_22 ', 'Google BigQuery')\n",
      "('P4_f_23 ', 'Google Firestore')\n",
      "('P4_f_24 ', 'Amazon Redshift')\n",
      "('P4_f_25 ', 'Amazon Athena')\n",
      "('P4_f_26 ', 'Snowflake')\n",
      "('P4_f_27 ', 'Databricks')\n",
      "('P4_f_28 ', 'HBase')\n",
      "('P4_f_29 ', 'Presto')\n",
      "('P4_f_30 ', 'Splunk')\n",
      "('P4_f_31 ', 'SAP HANA')\n",
      "('P4_f_32 ', 'Hive')\n",
      "('P4_f_33 ', 'Firebird')\n",
      "('P4_g ', 'Quais das opções de Cloud listadas abaixo você utiliza no trabalho?')\n",
      "('P4_h ', 'Dentre as opções listadas, qual sua Cloud preferida?')\n",
      "('P4_h_1 ', 'Azure (Microsoft)')\n",
      "('P4_h_2 ', 'Amazon Web Services (AWS)')\n",
      "('P4_h_3 ', 'Google Cloud (GCP)')\n",
      "('P4_i ', 'Microsoft PowerBI')\n",
      "('P4_i_1 ', 'Microsoft PowerBI')\n",
      "('P4_i_2 ', 'Qlik View/Qlik Sense')\n",
      "('P4_i_3 ', 'Tableau')\n",
      "('P4_i_4 ', 'Metabase')\n",
      "('P4_i_5 ', 'Superset')\n",
      "('P4_i_6 ', 'Redash')\n",
      "('P4_i_7 ', 'MicroStrategy')\n",
      "('P4_i_8 ', 'IBM Analytics/Cognos')\n",
      "('P4_i_9 ', 'SAP Business Objects')\n",
      "('P4_i_10 ', 'Oracle Business Intelligence')\n",
      "('P4_i_11 ', 'Amazon QuickSight')\n",
      "('P4_i_12 ', 'Salesforce/Einstein Analytics')\n",
      "('P4_i_13 ', 'Mode')\n",
      "('P4_i_14 ', 'Alteryx')\n",
      "('P4_i_15 ', 'Birst')\n",
      "('P4_i_16 ', 'Looker')\n",
      "('P4_i_17 ', 'Google Data Studio')\n",
      "('P4_i_18 ', 'SAS Visual Analytics')\n",
      "('P4_i_19 ', 'Grafana')\n",
      "('P4_i_20 ', 'TIBCO Spotfire')\n",
      "('P4_i_21 ', 'Pentaho')\n",
      "('P4_i_22 ', 'Fazemos todas as análises utilizando apenas Excel ou planilhas do google')\n",
      "('P4_i_23 ', 'Não utilizo nenhuma ferramenta de BI no trabalho')\n",
      "('P5_a ', 'Qual seu objetivo na área de dados?')\n",
      "('P5_b ', 'Qual oportunidade você está buscando?')\n",
      "('P5_c ', 'Há quanto tempo você busca uma oportunidade na área de dados?')\n",
      "('P5_d ', 'Como tem sido a busca por um emprego na área de dados?')\n",
      "('P6_a ', 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual como engenheiro de dados?')\n",
      "('P6_a_1 ', 'Desenvolvo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc.')\n",
      "('P6_a_2 ', 'Realizo construções de ETL's em ferramentas como Pentaho, Talend, Dataflow etc.')\n",
      "('P6_a_3 ', 'Crio consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\n",
      "('P6_a_4 ', 'Atuo na integração de diferentes fontes de dados através de plataformas proprietárias como Stitch Data, Fivetran etc.')\n",
      "('P6_a_5 ', 'Modelo soluções de arquitetura de dados, criando componentes de ingestão de dados, transformação e recuperação da informação.')\n",
      "('P6_a_6 ', 'Desenvolvo/cuido da manutenção de repositórios de dados baseados em streaming de eventos como Data Lakes e Data Lakehouses.')\n",
      "('P6_a_7 ', 'Atuo na modelagem dos dados, com o objetivo de criar conjuntos de dados como Data Warehouses, Data Marts etc.')\n",
      "('P6_a_8 ', 'Cuido da qualidade dos dados, metadados e dicionário de dados.')\n",
      "('P6_a_9 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\n",
      "('P6_b ', 'Quais as ferramentas/tecnologias de ETL que você utiliza no trabalho como Data Engineer?')\n",
      "('P6_b_1 ', 'Scripts Python')\n",
      "('P6_b_2 ', 'SQL & Stored Procedures')\n",
      "('P6_b_3 ', 'Apache Airflow')\n",
      "('P6_b_4 ', 'Luigi')\n",
      "('P6_b_5 ', 'AWS Glue')\n",
      "('P6_b_6 ', 'Talend')\n",
      "('P6_b_7 ', 'Pentaho')\n",
      "('P6_b_8 ', 'Alteryx')\n",
      "('P6_b_9 ', 'Stitch')\n",
      "('P6_b_10 ', 'Fivetran')\n",
      "('P6_b_11 ', 'Google Dataflow')\n",
      "('P6_b_12 ', 'Oracle Data Integrator')\n",
      "('P6_b_13 ', 'IBM DataStage')\n",
      "('P6_b_14 ', 'SAP BW ETL')\n",
      "('P6_b_15 ', 'SQL Server Integration Services (SSIS)')\n",
      "('P6_b_16 ', 'SAS Data Integration')\n",
      "('P6_b_17 ', 'Qlik Sense')\n",
      "('P6_b_18 ', 'Knime')\n",
      "('P6_b_19 ', 'Databricks')\n",
      "('P6_b_19 ', 'Não utilizo ferramentas de ETL')\n",
      "('P6_c ', 'Sua organização possui um Data Lake?')\n",
      "('P6_d ', 'Qual tecnologia utilizada como plataforma do Data Lake?')\n",
      "('P6_e ', 'Sua organização possui um Data Warehouse?')\n",
      "('P6_f ', 'Qual tecnologia utilizada como plataforma do Data Warehouse?')\n",
      "('P6_g ', 'Quais as ferramentas de gestão de Qualidade de dados, Metadados e catálogo de dados você utiliza no trabalho?')\n",
      "('P6_g_1 ', 'great_expectations')\n",
      "('P6_g_2 ', 'dbt')\n",
      "('P6_g_3 ', 'AWS Deequ')\n",
      "('P6_g_4 ', 'Apache Griffin')\n",
      "('P6_g_5 ', 'Datafold')\n",
      "('P6_g_6 ', 'Amundsen')\n",
      "('P6_g_7 ', 'Monte Carlo')\n",
      "('P6_g_8 ', 'SODA')\n",
      "('P6_g_9 ', 'Big Eye')\n",
      "('P6_g_10 ', 'Data Band')\n",
      "('P6_g_11 ', 'Anomalo')\n",
      "('P6_g_l ', 'Metaplane')\n",
      "('P6_g_m ', 'Acceldata')\n",
      "('P6_h ', 'Em qual das opções abaixo você gasta a maior parte do seu tempo?')\n",
      "('P6_h_1 ', 'Desenvolvendo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc.')\n",
      "('P6_h_2 ', 'Realizando construções de ETL's em ferramentas como Pentaho, Talend, Dataflow etc.')\n",
      "('P6_h_3 ', 'Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\n",
      "('P6_h_4 ', 'Atuando na integração de diferentes fontes de dados através de plataformas proprietárias como Stitch Data, Fivetran etc.')\n",
      "('P6_h_5 ', 'Modelando soluções de arquitetura de dados, criando componentes de ingestão de dados, transformação e recuperação da informação.')\n",
      "('P6_h_6 ', 'Desenvolvendo/cuidando da manutenção de repositórios de dados baseados em streaming de eventos como Data Lakes e Data Lakehouses.')\n",
      "('P6_h_7 ', 'Atuando na modelagem dos dados, com o objetivo de criar conjuntos de dados como Data Warehouses, Data Marts etc.')\n",
      "('P6_h_8 ', 'Cuidando da qualidade dos dados, metadados e dicionário de dados.')\n",
      "('P6_h_9 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\n",
      "('P7_1 ', 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual com análise de dados?')\n",
      "('P7_a_1 ', 'Processo e analiso dados utilizando linguagens de programação como Python, R etc.')\n",
      "('P7_a_2 ', 'Realizo construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik etc.')\n",
      "('P7_a_3 ', 'Crio consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\n",
      "('P7_a_4 ', 'Utilizo API's para extrair dados e complementar minhas análises.')\n",
      "('P7_a_5 ', 'Realizo experimentos e estudos utilizando metodologias estatísticas como teste de hipótese, modelos de regressão etc.')\n",
      "('P7_a_6 ', 'Desenvolvo/cuido da manutenção de ETL's utilizando tecnologias como Talend, Pentaho, Airflow, Dataflow etc.')\n",
      "('P7_a_7 ', 'Atuo na modelagem dos dados, com o objetivo de criar conjuntos de dados, Data Warehouses, Data Marts etc.')\n",
      "('P7_a_8 ', 'Desenvolvo/cuido da manutenção de planilhas para atender as áreas de negócio.')\n",
      "('P7_a_9 ', 'Utilizo ferramentas avançadas de estatística como SAS')\n",
      "('P7_a_10 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\n",
      "('P7_b ', 'Quais as ferramentas/tecnologias de ETL que você utiliza no trabalho como Data Analyst?')\n",
      "('P7_b_1 ', 'Scripts Python')\n",
      "('P7_b_2 ', 'SQL & Stored Procedures')\n",
      "('P7_b_3 ', 'Apache Airflow')\n",
      "('P7_b_4 ', 'Luigi')\n",
      "('P7_b_5 ', 'AWS Glue')\n",
      "('P7_b_6 ', 'Talend')\n",
      "('P7_b_7 ', 'Pentaho')\n",
      "('P7_b_8 ', 'Alteryx')\n",
      "('P7_b_9 ', 'Stitch')\n",
      "('P7_b_10 ', 'Fivetran')\n",
      "('P7_b_11 ', 'Google Dataflow')\n",
      "('P7_b_12 ', 'Oracle Data Integrator')\n",
      "('P7_b_13 ', 'IBM DataStage')\n",
      "('P7_b_14 ', 'SAP BW ETL')\n",
      "('P7_b_15 ', 'SQL Server Integration Services (SSIS)')\n",
      "('P7_b_16 ', 'SAS Data Integration')\n",
      "('P7_b_17 ', 'Qlik Sense')\n",
      "('P7_b_18 ', 'Knime')\n",
      "('P7_b_19 ', 'Databricks')\n",
      "('P7_b_20 ', 'Não utilizo ferramentas de ETL')\n",
      "('P7_c ', 'Sua empresa utiliza alguma das ferramentas listadas para dar mais autonomia em análise de dados para as áreas de negócio?')\n",
      "('P7_c_1 ', 'Ferramentas de AutoML como H2O.ai, Data Robot, BigML etc.')\n",
      "('P7_c_2 ', '\"\"Point and Click\"\" Analytics como Alteryx, Knime, Rapidminer etc.')\n",
      "('P7_c_3 ', 'Product metricts & Insights como Mixpanel, Amplitude, Adobe Analytics.')\n",
      "('P7_c_4 ', 'Ferramentas de análise dentro de ferramentas de CRM como Salesforce Einstein Anaytics ou Zendesk dashboards.')\n",
      "('P7_c_5 ', 'Minha empresa não utiliza essas ferramentas.')\n",
      "('P7_c_6 ', 'Não sei informar.')\n",
      "('P7_d ', 'Em qual das opções abaixo você gasta a maior parte do seu tempo de trabalho?')\n",
      "('P7_d_1 ', 'Processando e analisando dados utilizando linguagens de programação como Python, R etc.')\n",
      "('P7_d_2 ', 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik etc.')\n",
      "('P7_d_3 ', 'Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.')\n",
      "('P7_d_4 ', 'Utilizando API's para extrair dados e complementar minhas análises.')\n",
      "('P7_d_5 ', 'Realizando experimentos e estudos utilizando metodologias estatísticas como teste de hipótese, modelos de regressão etc.')\n",
      "('P7_d_6 ', 'Desenvolvendo/cuidando da manutenção de ETL's utilizando tecnologias como Talend, Pentaho, Airflow, Dataflow etc.')\n",
      "('P7_d_7 ', 'Atuando na modelagem dos dados, com o objetivo de criar conjuntos de dados, Data Warehouses, Data Marts etc.')\n",
      "('P7_d_8 ', 'Desenvolvendo/cuidando da manutenção de planilhas do Excel ou Google Sheets para atender as áreas de negócio.')\n",
      "('P7_d_9 ', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.')\n",
      "('P7_d_10 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\n",
      "('P8_a ', 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual com ciência de dados?')\n",
      "('P8_a_1 ', 'Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar modelos preditivos, forecasts, análise de cluster para resolver problemas pontuais e responder perguntas das áreas de negócio.')\n",
      "('P8_a_2 ', 'Sou responsável pela coleta e limpeza dos dados que uso para análise e modelagem.')\n",
      "('P8_a_3 ', 'Sou responsável por entrar em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.')\n",
      "('P8_a_4 ', 'Desenvolvo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).')\n",
      "('P8_a_5 ', 'Sou responsável por colocar modelos em produção, criar os pipelines de dados, APIs de consumo e monitoramento.')\n",
      "('P8_a_6 ', 'Cuido da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.')\n",
      "('P8_a_7 ', 'Realizo construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc')\n",
      "('P8_a_8 ', 'Utilizo ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises estatísticas e ajustar modelos.Crio e dou manutenção em ETLs, DAGs e automações de pipelines de dados.')\n",
      "('P8_a_9 ', 'Crio e dou manutenção em ETLs, DAGs e automações de pipelines de dados.')\n",
      "('P8_a_10 ', 'Crio e gerencio soluções de Feature Store e cultura de MLOps.')\n",
      "('P8_a_11 ', 'Sou responsável por criar e manter a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.)')\n",
      "('P8_b ', 'Quais as técnicas e métodos listados abaixo você costuma utilizar no trabalho?')\n",
      "('P8_b_1 ', 'Utilizo modelos de regressão (linear, logística, GLM)')\n",
      "('P8_b_2 ', 'Utilizo redes neurais ou modelos baseados em árvore para criar modelos de classificação')\n",
      "('P8_b_3 ', 'Desenvolvo sistemas de recomendação (RecSys)')\n",
      "('P8_b_4 ', 'Utilizo métodos estatísticos Bayesianos para analisar dados')\n",
      "('P8_b_5 ', 'Utilizo técnicas de NLP (Natural Language Processing) para análisar dados não-estruturados')\n",
      "('P8_b_6 ', 'Utilizo métodos estatísticos clássicos (Testes de hipótese, análise multivariada, sobrevivência, dados longitudinais, inferência estatistica) para analisar dados')\n",
      "('P8_b_7 ', 'Utilizo cadeias de Markov ou HMM's para realizar análises de dados')\n",
      "('P8_b_8 ', 'Desenvolvo técnicas de Clusterização (K-means, Spectral, DBScan etc)')\n",
      "('P8_b_9 ', 'Realizo previsões através de modelos de Séries Temporais (Time Series)')\n",
      "('P8_b_10 ', 'Utilizo modelos de Reinforcement Learning (aprendizado por reforço)')\n",
      "('P8_b_11 ', 'Utilizo modelos de Machine Learning para detecção de fraude')\n",
      "('P8_b_l ', 'Utilizo métodos de Visão Computacional')\n",
      "('P8_b_m ', 'Utilizo modelos de Detecção de Churn')\n",
      "('P8_3 ', 'Quais dessas tecnologias fazem parte do seu dia a dia como cientista de dados?')\n",
      "('P8_c_1 ', 'Ferramentas de BI (PowerBI, Looker, Tableau, Qlik etc)')\n",
      "('P8_c_2 ', 'Planilhas (Excel, Google Sheets etc)')\n",
      "('P8_c_3 ', 'Ambientes de desenvolvimento local (R-studio, JupyterLab, Anaconda)')\n",
      "('P8_c_4 ', 'Ambientes de desenvolvimento na nuvem (Google Colab, AWS Sagemaker, Kaggle Notebooks etc)')\n",
      "('P8_c_5 ', 'Ferramentas de AutoML (Datarobot, H2O, Auto-Keras etc)')\n",
      "('P8_c_6 ', 'Ferramentas de ETL (Apache Airflow, NiFi, Stitch, Fivetran, Pentaho etc)')\n",
      "('P8_c_7 ', 'Plataformas de Machine Learning (TensorFlow, Azure Machine Learning, Kubeflow etc)')\n",
      "('P8_c_8 ', 'Feature Store (Feast, Hopsworks, AWS Feature Store, Databricks Feature Store etc)')\n",
      "('P8_c_9 ', 'Sistemas de controle de versão (Github, DVC, Neptune, Gitlab etc)')\n",
      "('P8_c_10 ', 'Plataformas de Data Apps (Streamlit, Shiny, Plotly Dash etc)')\n",
      "('P8_c_11 ', 'Ferramentas de estatística avançada como SPSS, SAS, etc.')\n",
      "('P8_d ', 'Em qual das opções abaixo você gasta a maior parte do seu tempo no trabalho?')\n",
      "('P8_d_1 ', 'Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar modelos preditivos, forecasts, análise de cluster para resolver problemas pontuais e responder perguntas das áreas de negócio.')\n",
      "('P8_d_2 ', 'Coletando e limpando os dados que uso para análise e modelagem.')\n",
      "('P8_d_3 ', 'Entrando em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.')\n",
      "('P8_d_4 ', 'Desenvolvendo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).')\n",
      "('P8_d_5 ', 'Colocando modelos em produção, criando os pipelines de dados, APIs de consumo e monitoramento.')\n",
      "('P8_d_6 ', 'Cuidando da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.')\n",
      "('P8_d_7 ', 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc.')\n",
      "('P8_d_8 ', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.')\n",
      "('P8_d_9 ', 'Criando e dando manutenção em ETLs, DAGs e automações de pipelines de dados.')\n",
      "('P8_d_10 ', 'Criando e gerenciando soluções de Feature Store e cultura de MLOps.')\n",
      "('P8_d_11 ', 'Criando e mantendo a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.)')\n"
     ]
    }
   ],
   "source": [
    "extract_values_between_parentheses(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
